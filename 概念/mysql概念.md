### 一、数据库优化：

  数据库优化是一个庞大的层面

1：从需求解决（不合理的需求，直接砍掉）

2：从开发解决（避免复杂的查询 结合需求）

3：从数据分析：查看olap oltp采用合适的硬件，内存 cpu 网络 磁盘等因素

   4：选择合适的存储引擎

   5：建立合适的索引

   6：查询执行较慢的sql,查看 sql的执行计划分析执行慢的原因

 

### 二、Olap Oltp

OLTP 系统强调数据库内存效率，强调内存各种指标的命令率，强调绑定变量，强调并发操作；

OLAP 系统则强调数据分析，强调SQL执行市场，强调磁盘I/O，强调分区等。

 

联机分析处理（OLAP,On-line Analytical Processing）， 

系统则强调数据分析，强调SQL执行市场，强调磁盘I/O，强调分区等。 

特征：  数据量大，并发小，每次访问数据量多。没有明显活跃数据

优化：  每次访问数据量多:磁盘要注重吞吐量(每次访问的数据过大)

并发小：cpu可不注重

查询计算时间长：注意集群，和网络通讯不能间断

   联机事务处理（OLTP,On-line Transaction Processing），例如银行系统

系统强调数据库内存效率，强调内存各种指标的命令率，强调绑定变量，强调并发操作；

特征： 数据存储量大，并发多，DML频繁，单词查询数据量较少，活跃数据占比不大

优化方案：

活跃数据少：将活跃数据放入到缓存中

硬盘io频繁（iops多）： 采用io效率高频繁的硬盘

高并发：cpu 主频高，核多

与客户端交互频繁：网络要搞好

 

 

### 三、如何设计表(数据库三范式)

设计表呢一般遵循数据库的范式就可以了，数据库范式一共有六种，但是我们能遵循所常说的三范式就够了。第一范式能确保数据的原子性，并保证字段为不可拆分的最小单元即可。第二范式是在确保第一范式的情况下保证一张表只用来做一件事，一切跟这个表主键没关系的都不要，分离到其他相应表中。第三范式是在确保第二范式的情况下保证如果多表之间有关联，则只需要存一个其他表的主键即可，不存其他表多余字段，这就是我们在设计表时一般需要注意的地方。

同时注意，一个表尽量别超过60个字段，或有过多的冗余字段，

数据类型指定正确，并且长度合适，避免空间浪费

命名规范一般用模块_表名，禁止中划线， 

选择合适的引擎innodb mysam 效率会存在差别

注意选择utf8字符集，（支持汉字）

 

### 四、mysql 用show查看系统信息

show tables; 查看数据库中所有的表

show variables like '%max_connections%'; 查看最大连接数

set global max_connections=1000 重新设置

show processlist: 列出当前用户的前100条连接信息；

show full processlist: 列出当前用户的所有连接信息；

show PROFILES;展示所有sql的进程

show profile cpu,block io for query 74; 根据进程号查看sql使用cpu和内存情况

 

 

 

 

### 五、视图的概念和表的区别

简单的说表是独立的，每张表都对应一个或多个实际的存储文件，而视图是已经编译好的sql语句，可以是多张表中的数据，它本身不单独存储在数据库中，因此可以看做是一张虚拟的表，并不能存储实际的数据，也就不能进行增删改操作。 用create view sql创建，

 

### 六、Mysql中的锁

锁的种类分为共享锁 排它锁

  共享锁可以允许其他线程查询数据不允许修改

lock TABLES t_user read ;

 

排它锁不允许其他线程修改和查询数据

LOCK TABLE t_user WRITE;

 

   行锁：数据执行更新时候 如果能定位到精准数据，不进行全表扫描，会将更新的数据行进行锁定，其他线程在操作更新这些数据时候那就会进行阻塞等待，除非行锁释放才能进行更新操作，只有根据索引字段进行定位到精准数据的时候才会使用行锁，如果使用普通查询，造成全表扫描 会进行表锁。优点是粒度小，缺点就是加锁释放锁消耗性能，容易发生死锁现象。

 

   表锁：数据执行更新时候，查询条件如果是全表扫描的话，那么会进行行锁，其他线程在操作更新这张表据时候那就会进行阻塞等待，除非表锁释放才能进行更新操作，优点是逻辑简单，获取锁释放锁效率快，不会产生死锁，缺点：粒度太大，并发不够高

间隙锁：使用索引字段进行范围检索的时候，会对整个索引区间的值进行行锁，其他事务无法操作这个索引区间的数据

锁优化：尽可能的让所有数据的检索通过索引来完成

合理的设置索引

减少基于范围的数据是检索过滤条件

尽量控制事务的大小，事务过大会导致其他数据不能操作数据，造成阻塞

业务允许的情况下，尽量使用较低级别的隔离级别

 

 

​     

   Innodb采用的是共享锁，行锁表锁，间隙锁，数据在修改的时候，其他线程可以查询，不可以修改当sql执行完毕会释放锁，其他线程可以执行更新操作，

Myisam采用的是表锁，数据在操作的时候进行表锁，其他线程不可执行，操作完毕释放锁

 

死锁：死锁发生在innodb中, 两个事务同时开始执行，分别锁住了不同表的数据，然后再去操作互相的表数据的时候，那么需要各自等待，事务不完毕无法释放，这就是死锁，死锁发生后 可以show full PROCESSLIST

查看死锁的进程，然后kill 杀掉进程就可以了

 

 

 

 

 

### 七、千万级数据的优化

在数据库表达到千万的时候，查询效率已经很慢了，达到百万中筛选数据就需要1秒以上了，索引数据达到千万就很慢了，通过数据表达到百万通过增加索引就可以提高效率亲测做过实验，在千万数据以内，将查询的字段加上索引后，效率很快，在0.5毫秒内所以说，在千万级数据量，检索一条数据，通过加索引就可解决，然后一张表不单单只有单条数据查询，还有分页，也是麻烦事，千万数据下，一个count计算都需要10秒+所以，可过其他方式来处理，要么是牺牲系统的增删该功能，在表上加一个字段，从1开始递增，发生删除等操作需要更新这个状态，然后分页的时候，直接查询max(递增字段)就行，这是分页，

当数据量达到千万加入索引只能优化单条查询的效率，如果想提高效率可做分表，例如把数据拆分都不同表中，加上表名的限制，以年为单位距离，固定2018年数据必须存放在2018表中，2019年存放在2019年的表中，可将前千万的数据量分为N个百万即可

当数据库进行大量的更新删除查询互斥操作时，可酌情采用数据库引擎mysiam,一般是innodb，InnoDB的有点是支持事务但效率较低于mysiam，mysiam的数据存储结构与innodb不同要快上1-2倍

如果发生表联查，那基本上没有什么的优化空间了，只能做数据预处理操作，也就是将数据放入搜索引擎，让专业的查询技术来做这些数据，数据库本来就不善于这些计算操作，这个数据放入搜索引擎

还有就是经常重复的sql，如果经常查询同样 数据，每次都开启连接像数据库查询也是没必要的，这样的数据放入缓存，

最后，可采用数据库的主从来加大数据的连接数，配置一主一从，主库负责所有的增删改操作，从库负责所有的查询操作

 

 

### 八、Sql规范

首先sql优化的前提是数据量很大的时候，我们可以利用好索引，并尽量避免全表扫描，比如说：在where和order by涉及的列上建立索引，尽量避免在where中对字段进行null值得判断，尽量避免使用!=或者<>操作符，尽量避免使用or来链接条件，尽量避免使用in和not in，尽量避免对字段进行表达式操作等等。

程序界的二八定律，百分之20的sql占用了百分之80的数据库资源， 

不使用子查询 

避免函数索引 

LIKE双百分号无法使用到索引 

避免数据类型不一致 

批量INSERT插入 

limit千万级分页的时候优化。 

在我们平时用limit,如： 

Select * from A order by id limit 1,10; 

这样在表数据很少的时候，看不出什么性能问题，倘若到达千万级，如： 

Select * from A order by id limit10000000,10; 

虽然都是只查询10记录，但是这个就性能就让人受不了了。所以为什么当表数据很大的时 候，我们 

还继续用持久层框架如hibernate,ibatis就会有一些性能问题，除非持久层框架对 这些大数据表做过优 

化。 

在遇见上面的情况，我们可以用另外一种语句优化，如： 

Select * from A where id>=(Select id from a limit 10000000,1) limit 10; 

确实这样快了很多，不过前提是，id字段建立了索引。也许这个还不是最优的，其实还可 以这样写： 

Select * from A where id between 10000000 and 10000010; 

这样的效率更加高。 

Innerjoin和左连接，右连接， 

子查询经过来之多方面的证实inner join性能比较快，因为inner join是等值连接，或许返 回的行数比 

较少。但是我们要记得有些语句隐形的用到了等值连接，如推荐：能用inner join 连接尽量使用inner join 

连接

mysql的where条件后条件是从左到右 

多个字段比较时，最能精确筛选到数据的字段放在最左边，例如id=1 and age=18 

Id是唯一的，能更精确的筛选到数据，所以放在最左边 

Oracle的顺序是从右到左 如果是oracle id=1放在最右边

 

### 九、Sql优化：

Sql优化可以使用expain 执行计划来看一下sql的执行过程， 

Id:是否属于同一个sql进程

select_type ：查询的类型，主要是用于区分普通查询、联合查询、子查询等复杂的查询

Table：一列表示 explain 的一行正在访问哪个表。

Type：这列表示关联类型或访问类型，即MySQL决定如何查找表中的行。

依次从最优到最差分别为：system >const > eq_ref > ref > fulltext > ref_or_null > index_merge >unique_subquery > index_subquery > range > index > ALL

possible_keys：这一列显示查询可能使用哪些索引来查找。 

Key：这一列显示mysql实际采用哪个索引来优化对该表的访问。

key_len：表示索引中使用的字节数，查询中使用的索引的长度（最大可能长度），

ref:显示索引的那一列被使用了，如果可能，是一个常量const。

rows:根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数

Extra:不适合在其他字段中显示，但是十分重要的额外信息

总结，根据执行计划，看一下 是否定位到索引，是否用小结果集驱动大结果集，是否可以检索出的数据量最小，等

 

Join优化

  Join发生在两表联查之间 取出关联的列和数据放入 joinbuffer缓冲区，进行比对，匹配结果集，匹配好之后返回给查询结果，如果joinbuffer不够大的话那么就会造成磁盘存储创建临时表，就会变慢，所以优化的话可以注意只取出需要的列数据，然后将joinbuffer设置成合适大小就可以，数据可以放进去，具体大小需要根据实际的业务和数据量和计算

show VARIABLES LIKE 'join%' 查看缓冲区大小

   order by 优化

如果按照索引字段进行排序，那么效率非常快，因为索引本身就是有序的，但是如果排序列没有索引的 话，那么会将排序列，和数据行，取出来放入sortbuffer排序缓冲区，排序后返回给查询结果集。也需要注意sort缓冲区的大小问题

show VARIABLES LIKE 'sort%' 查看排序缓冲区大小

​    group by 优化

   分组的过程就是先排序在分组，优化排序就可以了

   Limit优化

   Limit比较常用  且 执行计划的type=all 性能最差全表扫描，不走索引

   常规写法 limit 100000,10 从10w条之后查询10条，性能很差，可以改为

优化为  SELECT * from t_user1 where user_id> 100000 limit 10

这样可以走索引，避免全表扫描，提高效率，但是需要维护保证 大于字段是有序且准确的

   

 

 

​     

 

 

 

### 十、Mysql的索引

索引，作用就是加快查询的速度，所以在数据量小的时候，本身查询速度就很快，就没必要添加索引，并且索引也不是越多越好，过多的索引对数据库也会带来一定的负担。MySQL中的索引有以下几种：普通索引，唯一索引，主键索引，组合索引等。索引加在条件查询的字段上，表的业务特性必须是多查询，少修改的，否者加索引一定能查询效率，索引提高的是查询效率，牺牲的是增删改效率，

索引只能提升条件查询效率，如果项目中做分页，或者聚合函数查询，索引解决不了问题，可以做分表优化，或者数据预处理操作

ALTER TABLE 表名称 ADD 索引类型 ( `列名称` )

 

索引的原理，就是将列加入索引后，会自动将此列的数据抽离出来，经过hash或btree算法 排序后放入索引层，形成一个树结构，每个节点都是此列的值，通过记录值所在的行位置，然后在sql执行的时候，如果此列加入条件查询，会先根据条件，在索引层查找数据，根据树的特性，每次折半查找，所以能很快定位数据的位置，然后根据数据位置直接取出数据，无需进行全表扫描，这就是索引的原理

 

索引通常加载，所有从表的外键上，以及条件查询的字段上，经常被查询很少被修改的表中

 

MySQL主要提供2种方式的索引：B+‐Tree索引，Hash索引 

B+树索引具有范围查找和前缀查找的能力，最底层节点存储的是全部数据，是有序的所以可以做范围查找，对于有N节点的B树，检索一条记录的复杂度 为 

O(LogN)。相当于二分查找。 

哈希索引只能做等于查找，所有索引数据以树结构展示，是无序的所以无法进行返回查询， 但是无论多大的Hash表，查找复杂度都是O(1)。 

显然，如果值的差异性大，并且以等值查找（=、 <、>、in）为主，Hash索引是更高效的 选择，它有O(1)的查找复杂度。 

如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找

 

索引失效 ：

1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因) 

要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 

2.对于多列索引，不是使用的第一部分，则不会使用索引 

3.like查询以%开头 

4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 

​     这些是一些基本规范，sql查询是否定位到索引查询，可以用expain来查询sql执行计划可以清晰的看到是否定位到索引查询

 

 

 

 

### 十一、Mysql引擎

 

mysql比较常用的数据库引擎有两种，一种是innodb、一种是myisam,在创建表的时候 选择合适的搜索引擎也是数据库层优化的一个重要节点，

innodb支持表锁，行锁，间隙锁， 支持事务，

myisam 支持表锁，不支持事务，

所以myisam的性能会好一些，没有事务，没有行锁，所以也不会死锁，

Innodb使用聚簇索引，数据和索引存储在同一个文件中， 数据本身挂在索引树的叶子节点上，

  Myisam使用的是非聚簇 ，数据文件和索引文件是分开的，叶子节点上只记录了数据行的地址，使用索引查询数据的时候需要进行二次查询才能定位到数据，

 

 

### 十二、Mysql主从分库

在实际的生产环境中，由单台Mysql作为独立的数据库是不太能满足实际需求的，无论是在安全性，高可用性，及高并发等各个方面。因此我们可以通过实现主从复制的方式来同步数据，再通过读写分离来提升数据库的并发负载能力。开启主从的步骤大致为：主服务器给从服务器授权，修改从服务器的my。cnf文件中的server-id，保证不重复，并执行同步sql语句指向主服务器，最后启动同步进程即可。

 

在数据库并发大的情况下，最好的做法就是进行横向扩展，增加机器，以提升抗并发能力，而且还兼

有数据备份功能，

设置主库和从库，根据主库的数据会时时同步到从库，所以控制程序中的inser,delte update走主

库，所有的select走从库，可以避免修改查询之间的表锁冲突，也可加大一倍的连接数

 

 

### 十三、Mysql分表

在项目开发过程中数据库的优化很重要，为了提高程序的健壮性，通常用分表来解决数据多的问题，很多项目第一年运营时，效率很快，但随着时间增多，数据也过多，没有经过特殊处理，全部放在一张表进行累加，导致查询变慢，可通过分表来解决这个问题，

例如商品订单表举例，通过按年份分表，就是说订单每年都是变成一张新表，2018_order,2017_order,不同年份的数据存储在不同的表中，那么就保证了，数据能平均到每张表，简介提高查询效率，需要注意的是，在页面查询的时候由于在订单根据年份在不同的表中所以不能查询全部数据，所以加上条件，只能根据年为单位查询数据，如果真的要查询所有年份的数据，可通过union查询就行，

例入用户表，可通过手机号前三位进行分表，例如151_user,152_user,用户登陆注册的数据，可通过手机号码前三位，将上亿的数据平均分配到多张表中，然后用户登陆的时候，肯定要输入手机号，咱们只要截取手机号的三千位，就可以定位到表，从对应的表中查询数据就行

分表后，主键就不能用自动递增了，会重复，需要使用一定算法生成

### 十四、悲乐观锁

乐观锁和悲观锁是两种常见的对资源并发锁的设计思路，悲观锁是在对数据修改时认为别人也会修改该数据，所以在操作数据时会对数据上锁，这样别人要操作该数据就会被阻塞，需要等待锁被释放，悲观锁的原理就是用到了数据库提供的锁机制。而乐观锁恰恰相反，在对数据修改时认为没有别人要修改该数据，所以不会上锁，但是在修改前会判断一下在此期间有没有人修改过这个数据，利用的是版本号机制，添加一个version字段就可以了。这两种锁各有优缺点，当写操作少读操作多时使用乐观锁可以增加吞吐量，反之则应该使用悲观锁。

 

 

 

### 十五、数据预处理

一般来说，实时数据(当天的数据)还是比较有限的，真正数据量比较大的是历史数据，基于大表历史

数据的查询，如果再涉及一些大表关联，这种sql是非常难以优化的

a、实时数据(当天数据)

通过对对业务的抽象，可以放在redis缓存里面，提升系统运行效率

b、历史数据，大数据表历史数据且有表关联，通过常规sql难以优化，但是该数据通常有个共性，就

是第二天去查询前一天的数据做分析报表，也就是说对时效性要求不高，这种情况的解决方案是预处理

做法是将这些复杂表关联sql写成个定时任务在半夜执行，将执行的结果存入到一张结果表中，第二

天直接查询结果表,如此，效率能得到十分明显提升

c、和b类似，可以将表关联结果存入solr或者elas蛣search中，以此提升效率，目前我们的项目就是如

此处理

### 十六、分布式事务

Tcc方案补偿性事务方案

TCC 的全称是：Try、Confirm、Cancel。

Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。

Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。

Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）

正在最后的代码去时候的时候加判断，如果成功提交事务，如果失败把之前增加的数据删掉

 

 

队列通知方案

系统 A 本地事务执行完之后，发送个消息到 MQ；

这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；

要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。

### 